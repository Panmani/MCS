2020-10-16 15:15:38,239 training args:Namespace(cfg='./cfgs/vcr/large_q2a_16x16G_fp16.yaml', cudnn_off=False, dist=False, do_test=False, log_dir='my_ckpt/./output/vl-bert/vcr/large_q2a_16x16G_fp16/vcr1images_train/tensorboard_logs', model_dir='my_ckpt', partial_pretrain=None, slurm=False)

2020-10-16 15:15:38,243 training config:{'CHECKPOINT_FREQUENT': 1,
 'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'APPEND_INDEX': False,
             'BASIC_ALIGN': False,
             'CACHE_MODE': False,
             'DATASET': 'vcr',
             'DATASET_PATH': './data/vcr',
             'IGNORE_DB_CACHE': True,
             'LABEL_INDEX_IN_BATCH': 7,
             'MASK_SIZE': 14,
             'ONLY_USE_RELEVANT_DETS': False,
             'QA2R_AUG': False,
             'QA2R_NOQ': False,
             'ROOT_PATH': './',
             'TASK': 'Q2A',
             'TEST_ANNOTATION_FILE': 'test.jsonl',
             'TEST_IMAGE_SET': 'vcr1images',
             'TRAIN_ANNOTATION_FILE': 'train.jsonl',
             'TRAIN_IMAGE_SET': 'vcr1images',
             'VAL_ANNOTATION_FILE': 'val.jsonl',
             'VAL_IMAGE_SET': 'vcr1images',
             'ZIP_MODE': False},
 'GPUS': '0,1,2,3',
 'LOG_FREQUENT': 100,
 'MODEL_PREFIX': 'vl-bert_large_a_res101',
 'MODULE': 'ResNetVLBERT',
 'NETWORK': {'ANSWER_FIRST': False,
             'ANS_LOSS_WEIGHT': 1.0,
             'BERT_ALIGN_ANSWER': True,
             'BERT_ALIGN_QUESTION': True,
             'BERT_FROZEN': False,
             'BERT_MODEL_NAME': './model/pretrained_model/bert-large-uncased',
             'BERT_PRETRAINED': '',
             'BERT_PRETRAINED_EPOCH': 0,
             'BERT_USE_LAYER': -2,
             'BERT_WITH_MLM_LOSS': False,
             'BERT_WITH_NSP_LOSS': False,
             'BLIND': False,
             'CLASSIFIER_DROPOUT': 0.1,
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'CLASSIFIER_SIGMOID': True,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'CLASSIFIER_TYPE': '1fc',
             'CNN_LOSS_TOP': True,
             'CNN_LOSS_WEIGHT': 1.0,
             'CNN_REG_DROPOUT': 0.0,
             'ENABLE_CNN_REG_LOSS': True,
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'IMAGE_C5_DILATED': True,
             'IMAGE_FEAT_PRECOMPUTED': False,
             'IMAGE_FINAL_DIM': 1024,
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'IMAGE_FROZEN_BN': True,
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_PRETRAINED': './model/pretrained_model/resnet101-pt-vgbua',
             'IMAGE_PRETRAINED_EPOCH': 0,
             'IMAGE_SEMANTIC': False,
             'IMAGE_STRIDE_IN_1x1': True,
             'LOAD_REL_HEAD': True,
             'NO_GROUNDING': False,
             'NO_OBJ_ATTENTION': False,
             'OUTPUT_CONV5': False,
             'PARTIAL_PRETRAIN': './model/pretrained_model/vl-bert-large-e2e.model',
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': ['vlbert.mvrc_head.transform->cnn_loss_reg.0',
                                                 'module.vlbert.mvrc_head.transform->module.cnn_loss_reg.0',
                                                 'module.vlbert->module.vlbert._module',
                                                 'vlbert->vlbert._module'],
             'PARTIAL_PRETRAIN_SEGMB_INIT': True,
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'QA_ONE_SENT': False,
             'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'hidden_act': 'gelu',
                        'hidden_dropout_prob': 0.1,
                        'hidden_size': 1024,
                        'initializer_range': 0.02,
                        'input_size': 1280,
                        'input_transform_type': 1,
                        'intermediate_size': 4096,
                        'max_position_embeddings': 512,
                        'num_attention_heads': 16,
                        'num_hidden_layers': 24,
                        'obj_pos_id_relative': True,
                        'object_word_embed_mode': 2,
                        'position_padding_idx': -1,
                        'type_vocab_size': 3,
                        'visual_ln': True,
                        'visual_scale_object_init': 0.0,
                        'visual_scale_text_init': 0.0,
                        'visual_size': 1024,
                        'vocab_size': 30522,
                        'with_pooler': True,
                        'word_embedding_frozen': False}},
 'NUM_WORKERS_PER_GPU': 4,
 'OUTPUT_PATH': 'my_ckpt/./output/vl-bert/vcr',
 'RNG_SEED': 12345,
 'SCALES': [600, 1200],
 'TEST': {'BATCH_IMAGES': 4, 'FLIP_PROB': 0, 'SHUFFLE': False, 'TEST_EPOCH': 0},
 'TRAIN': {'ASPECT_GROUPING': False,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 4,
           'BEGIN_EPOCH': 0,
           'CLIP_GRAD_NORM': 10,
           'END_EPOCH': 20,
           'FLIP_PROB': 0.5,
           'FP16': True,
           'FP16_LOSS_SCALE': 'dynamic',
           'GRAD_ACCUMULATE_STEPS': 1,
           'LOSS_LOGGERS': [('ans_loss', 'AnsLoss'),
                            ('cnn_regularization_loss', 'CNNRegLoss')],
           'LR': 7e-05,
           'LR_FACTOR': 0.1,
           'LR_MULT': [],
           'LR_SCHEDULE': 'step',
           'LR_STEP': [14.0, 18.0],
           'MOMENTUM': 0.9,
           'OPTIMIZER': 'SGD',
           'RESUME': False,
           'SHUFFLE': True,
           'VISUAL_SCALE_CLIP_GRAD_NORM': -1,
           'VISUAL_SCALE_OBJECT_LR_MULT': 1.0,
           'VISUAL_SCALE_TEXT_LR_MULT': 1.0,
           'WARMUP': True,
           'WARMUP_FACTOR': 0.0,
           'WARMUP_METHOD': 'linear',
           'WARMUP_STEPS': 1000,
           'WD': 0.0001},
 'VAL': {'BATCH_IMAGES': 4, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'VAL_FREQUENT': 1}

2020-10-16 15:15:38,779 Model name './model/pretrained_model/bert-large-uncased' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese). We assumed './model/pretrained_model/bert-large-uncased' was a path or url but couldn't find any file associated to this path or url.
2020-10-16 15:15:41,468 >> Trainable Parameters:
2020-10-16 15:15:41,471 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,471 |Name                                                                        |Dtype            |Shape                 |#Params     |
2020-10-16 15:15:41,471 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,471 |image_feature_extractor.backbone.layer2.0.conv1.weight                      |torch.float32    |(128, 256, 1, 1)      |32768       |
2020-10-16 15:15:41,471 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,471 |image_feature_extractor.backbone.layer2.0.conv2.weight                      |torch.float32    |(128, 128, 3, 3)      |147456      |
2020-10-16 15:15:41,471 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,471 |image_feature_extractor.backbone.layer2.0.conv3.weight                      |torch.float32    |(512, 128, 1, 1)      |65536       |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.0.downsample.0.weight               |torch.float32    |(512, 256, 1, 1)      |131072      |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.1.conv1.weight                      |torch.float32    |(128, 512, 1, 1)      |65536       |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.1.conv2.weight                      |torch.float32    |(128, 128, 3, 3)      |147456      |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.1.conv3.weight                      |torch.float32    |(512, 128, 1, 1)      |65536       |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.2.conv1.weight                      |torch.float32    |(128, 512, 1, 1)      |65536       |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.2.conv2.weight                      |torch.float32    |(128, 128, 3, 3)      |147456      |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.2.conv3.weight                      |torch.float32    |(512, 128, 1, 1)      |65536       |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.3.conv1.weight                      |torch.float32    |(128, 512, 1, 1)      |65536       |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.3.conv2.weight                      |torch.float32    |(128, 128, 3, 3)      |147456      |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer2.3.conv3.weight                      |torch.float32    |(512, 128, 1, 1)      |65536       |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer3.0.conv1.weight                      |torch.float32    |(256, 512, 1, 1)      |131072      |
2020-10-16 15:15:41,472 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,472 |image_feature_extractor.backbone.layer3.0.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,473 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,473 |image_feature_extractor.backbone.layer3.0.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,473 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,473 |image_feature_extractor.backbone.layer3.0.downsample.0.weight               |torch.float32    |(1024, 512, 1, 1)     |524288      |
2020-10-16 15:15:41,473 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,473 |image_feature_extractor.backbone.layer3.1.conv1.weight                      |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,473 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,473 |image_feature_extractor.backbone.layer3.1.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,474 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,474 |image_feature_extractor.backbone.layer3.1.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,474 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,474 |image_feature_extractor.backbone.layer3.2.conv1.weight                      |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,474 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,474 |image_feature_extractor.backbone.layer3.2.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,474 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,474 |image_feature_extractor.backbone.layer3.2.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,474 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,474 |image_feature_extractor.backbone.layer3.3.conv1.weight                      |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,474 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,474 |image_feature_extractor.backbone.layer3.3.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,474 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,474 |image_feature_extractor.backbone.layer3.3.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,474 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,474 |image_feature_extractor.backbone.layer3.4.conv1.weight                      |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,474 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,474 |image_feature_extractor.backbone.layer3.4.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.4.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.5.conv1.weight                      |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.5.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.5.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.6.conv1.weight                      |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.6.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.6.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.7.conv1.weight                      |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.7.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.7.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.8.conv1.weight                      |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.8.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,475 |image_feature_extractor.backbone.layer3.8.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,475 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.9.conv1.weight                      |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.9.conv2.weight                      |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.9.conv3.weight                      |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.10.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.10.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.10.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.11.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.11.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.11.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.12.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.12.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.12.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.13.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.13.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,476 |image_feature_extractor.backbone.layer3.13.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,476 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.14.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.14.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.14.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.15.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.15.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.15.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.16.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.16.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.16.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.17.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.17.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.17.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.18.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.18.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.18.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,477 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,477 |image_feature_extractor.backbone.layer3.19.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.19.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.19.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.20.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.20.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.20.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.21.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.21.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.21.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.22.conv1.weight                     |torch.float32    |(256, 1024, 1, 1)     |262144      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.22.conv2.weight                     |torch.float32    |(256, 256, 3, 3)      |589824      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.backbone.layer3.22.conv3.weight                     |torch.float32    |(1024, 256, 1, 1)     |262144      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.roi_head_feature_extractor.0.conv1.weight           |torch.float32    |(512, 1024, 1, 1)     |524288      |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.roi_head_feature_extractor.0.conv2.weight           |torch.float32    |(512, 512, 3, 3)      |2359296     |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.roi_head_feature_extractor.0.conv3.weight           |torch.float32    |(2048, 512, 1, 1)     |1048576     |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.roi_head_feature_extractor.0.downsample.0.weight    |torch.float32    |(2048, 1024, 1, 1)    |2097152     |
2020-10-16 15:15:41,478 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,478 |image_feature_extractor.roi_head_feature_extractor.1.conv1.weight           |torch.float32    |(512, 2048, 1, 1)     |1048576     |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |image_feature_extractor.roi_head_feature_extractor.1.conv2.weight           |torch.float32    |(512, 512, 3, 3)      |2359296     |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |image_feature_extractor.roi_head_feature_extractor.1.conv3.weight           |torch.float32    |(2048, 512, 1, 1)     |1048576     |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |image_feature_extractor.roi_head_feature_extractor.2.conv1.weight           |torch.float32    |(512, 2048, 1, 1)     |1048576     |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |image_feature_extractor.roi_head_feature_extractor.2.conv2.weight           |torch.float32    |(512, 512, 3, 3)      |2359296     |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |image_feature_extractor.roi_head_feature_extractor.2.conv3.weight           |torch.float32    |(2048, 512, 1, 1)     |1048576     |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |image_feature_extractor.obj_downsample.1.weight                             |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |image_feature_extractor.obj_downsample.1.bias                               |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |object_linguistic_embeddings.weight                                         |torch.float32    |(1, 1024)             |1024        |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |cnn_loss_reg.0.dense.weight                                                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |cnn_loss_reg.0.dense.bias                                                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |cnn_loss_reg.2.weight                                                       |torch.float32    |(81, 1024)            |82944       |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |cnn_loss_reg.2.bias                                                         |torch.float32    |(81,)                 |81          |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |vlbert._module.word_embeddings.weight                                       |torch.float32    |(30522, 1024)         |31254528    |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |vlbert._module.end_embedding.weight                                         |torch.float32    |(1, 1024)             |1024        |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,479 |vlbert._module.position_embeddings.weight                                   |torch.float32    |(512, 1024)           |524288      |
2020-10-16 15:15:41,479 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.token_type_embeddings.weight                                 |torch.float32    |(3, 1024)             |3072        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.embedding_LayerNorm.weight                                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.embedding_LayerNorm.bias                                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.visual_ln_text.weight                                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.visual_ln_text.bias                                          |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.visual_ln_object.weight                                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.visual_ln_object.bias                                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.encoder.layer.0.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.encoder.layer.0.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.encoder.layer.0.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.encoder.layer.0.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.encoder.layer.0.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.encoder.layer.0.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.encoder.layer.0.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.encoder.layer.0.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,480 |vlbert._module.encoder.layer.0.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,480 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.0.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.0.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.0.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.0.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.0.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.0.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.0.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.1.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.1.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.1.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.1.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.1.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.1.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.1.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.1.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,481 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,481 |vlbert._module.encoder.layer.1.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.1.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.1.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.1.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.1.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.1.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.1.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.1.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.2.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.2.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.2.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.2.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.2.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,482 |vlbert._module.encoder.layer.2.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,482 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.2.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.3.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.3.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.3.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.3.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,483 |vlbert._module.encoder.layer.3.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,483 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,484 |vlbert._module.encoder.layer.3.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,484 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.3.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,485 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,485 |vlbert._module.encoder.layer.4.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.4.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.4.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.4.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,486 |vlbert._module.encoder.layer.5.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,486 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.5.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.5.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.5.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.5.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,487 |vlbert._module.encoder.layer.6.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,487 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.6.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.6.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.6.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.6.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,488 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,488 |vlbert._module.encoder.layer.7.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.7.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.7.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.7.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.7.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,489 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,489 |vlbert._module.encoder.layer.8.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.8.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.8.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.8.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.8.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.self.query.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.self.query.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.self.key.weight                    |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.self.key.bias                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.self.value.weight                  |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.self.value.bias                    |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.output.dense.weight                |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.output.dense.bias                  |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.output.LayerNorm.weight            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,490 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,490 |vlbert._module.encoder.layer.9.attention.output.LayerNorm.bias              |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.9.intermediate.dense.weight                    |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.9.intermediate.dense.bias                      |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.9.output.dense.weight                          |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.9.output.dense.bias                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.9.output.LayerNorm.weight                      |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.9.output.LayerNorm.bias                        |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.10.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.10.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.10.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.10.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.10.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.10.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.10.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.10.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,491 |vlbert._module.encoder.layer.10.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,491 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.10.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.10.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.10.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.10.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.10.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.10.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.10.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.11.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.11.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.11.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.11.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.11.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.11.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.11.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.11.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,492 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,492 |vlbert._module.encoder.layer.11.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.11.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.11.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.11.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.11.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.11.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.11.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.11.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.12.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.12.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.12.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.12.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.12.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.12.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.12.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,493 |vlbert._module.encoder.layer.12.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,493 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.12.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.12.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.12.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.12.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.12.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.12.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.12.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.12.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.13.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.13.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.13.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.13.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.13.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.13.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,494 |vlbert._module.encoder.layer.13.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,494 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.13.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,495 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.13.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,495 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.13.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,495 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.13.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,495 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.13.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,495 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.13.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,495 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.13.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,495 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.13.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,495 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.13.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,495 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,495 |vlbert._module.encoder.layer.14.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,496 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,496 |vlbert._module.encoder.layer.14.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,497 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,497 |vlbert._module.encoder.layer.15.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,498 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,498 |vlbert._module.encoder.layer.16.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,499 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,499 |vlbert._module.encoder.layer.17.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.17.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,500 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,500 |vlbert._module.encoder.layer.18.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.18.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,501 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,501 |vlbert._module.encoder.layer.19.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.19.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,502 |vlbert._module.encoder.layer.20.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,502 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.20.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.20.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.20.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,503 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,503 |vlbert._module.encoder.layer.21.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.21.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.21.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.21.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,504 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,504 |vlbert._module.encoder.layer.22.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.22.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.22.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.22.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.22.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.22.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.22.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.23.attention.self.query.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.23.attention.self.query.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.23.attention.self.key.weight                   |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.23.attention.self.key.bias                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.23.attention.self.value.weight                 |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.23.attention.self.value.bias                   |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,505 |vlbert._module.encoder.layer.23.attention.output.dense.weight               |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,505 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.encoder.layer.23.attention.output.dense.bias                 |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.encoder.layer.23.attention.output.LayerNorm.weight           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.encoder.layer.23.attention.output.LayerNorm.bias             |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.encoder.layer.23.intermediate.dense.weight                   |torch.float32    |(4096, 1024)          |4194304     |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.encoder.layer.23.intermediate.dense.bias                     |torch.float32    |(4096,)               |4096        |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.encoder.layer.23.output.dense.weight                         |torch.float32    |(1024, 4096)          |4194304     |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.encoder.layer.23.output.dense.bias                           |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.encoder.layer.23.output.LayerNorm.weight                     |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.encoder.layer.23.output.LayerNorm.bias                       |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.pooler.dense.weight                                          |torch.float32    |(1024, 1024)          |1048576     |
2020-10-16 15:15:41,506 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,506 |vlbert._module.pooler.dense.bias                                            |torch.float32    |(1024,)               |1024        |
2020-10-16 15:15:41,507 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,507 |final_mlp.1.weight                                                          |torch.float32    |(1, 1024)             |1024        |
2020-10-16 15:15:41,507 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,507 |final_mlp.1.bias                                                            |torch.float32    |(1,)                  |1           |
2020-10-16 15:15:41,507 ------------------------------------------------------------------------------------------------------------------------------------
2020-10-16 15:15:41,511 >> # TrainableParams:       	382.65	M
2020-10-16 15:15:41,511 >> # NonTrainableParams:    	0.33	M
2020-10-16 15:15:41,511 >> # TotalParams:           	382.98	M
